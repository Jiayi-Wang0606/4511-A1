{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6cnuwbr7aUJs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting bertopic\n","  Downloading bertopic-0.16.0-py2.py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.1/154.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.25.2)\n","Collecting hdbscan\u003e=0.8.29 (from bertopic)\n","  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting umap-learn\u003e=0.5.0 (from bertopic)\n","  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pandas\u003e=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n","Requirement already satisfied: scikit-learn\u003e=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\n","Requirement already satisfied: tqdm\u003e=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n","Collecting sentence-transformers\u003e=0.4.1 (from bertopic)\n","  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: plotly\u003e=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n","Collecting cython\u003c3,\u003e=0.27 (from hdbscan\u003e=0.8.29-\u003ebertopic)\n","  Using cached Cython-0.29.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n","Requirement already satisfied: scipy\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan\u003e=0.8.29-\u003ebertopic) (1.11.4)\n","Requirement already satisfied: joblib\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan\u003e=0.8.29-\u003ebertopic) (1.3.2)\n","Requirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003e=1.1.5-\u003ebertopic) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003e=1.1.5-\u003ebertopic) (2023.4)\n","Requirement already satisfied: tenacity\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly\u003e=4.7.0-\u003ebertopic) (8.2.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly\u003e=4.7.0-\u003ebertopic) (23.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.22.2.post1-\u003ebertopic) (3.3.0)\n","Requirement already satisfied: transformers\u003c5.0.0,\u003e=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (4.37.2)\n","Requirement already satisfied: torch\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (2.1.0+cu121)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (3.8.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (0.1.99)\n","Requirement already satisfied: huggingface-hub\u003e=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=0.4.1-\u003ebertopic) (9.4.0)\n","Requirement already satisfied: numba\u003e=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn\u003e=0.5.0-\u003ebertopic) (0.58.1)\n","Collecting pynndescent\u003e=0.5 (from umap-learn\u003e=0.5.0-\u003ebertopic)\n","  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (3.13.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2.31.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (6.0.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (4.9.0)\n","Requirement already satisfied: llvmlite\u003c0.42,\u003e=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba\u003e=0.51.2-\u003eumap-learn\u003e=0.5.0-\u003ebertopic) (0.41.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.1-\u003epandas\u003e=1.1.5-\u003ebertopic) (1.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (3.1.3)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c5.0.0,\u003e=4.32.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2023.12.25)\n","Requirement already satisfied: tokenizers\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c5.0.0,\u003e=4.32.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (0.15.2)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c5.0.0,\u003e=4.32.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (0.4.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (8.1.7)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2.1.5)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.15.1-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (2024.2.2)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.11.0-\u003esentence-transformers\u003e=0.4.1-\u003ebertopic) (1.3.0)\n","Building wheels for collected packages: hdbscan, umap-learn\n","  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp310-cp310-linux_x86_64.whl size=3039299 sha256=3c404decf311121cf387013aec32918383eb83ad182d34bb30c4f62675d76385\n","  Stored in directory: /root/.cache/pip/wheels/75/0b/3b/dc4f60b7cc455efaefb62883a7483e76f09d06ca81cf87d610\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86832 sha256=e629abf74e482c3d3658127763a6e9869b12aa67f5ed1df093b9db3fb4748285\n","  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n","Successfully built hdbscan umap-learn\n","Installing collected packages: cython, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n","  Attempting uninstall: cython\n","    Found existing installation: Cython 3.0.8\n","    Uninstalling Cython-3.0.8:\n","      Successfully uninstalled Cython-3.0.8\n","Successfully installed bertopic-0.16.0 cython-0.29.37 hdbscan-0.8.33 pynndescent-0.5.11 sentence-transformers-2.3.1 umap-learn-0.5.5\n"]}],"source":["pip install bertopic"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Djf1BC3SaN8r"},"outputs":[],"source":["from bertopic import BERTopic\n","from sklearn.datasets import fetch_20newsgroups\n","from sklearn.cluster import KMeans"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eQontVIUa1r4"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"encoding with 'zlib_codec' codec failed (KeyboardInterrupt: )","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.10/encodings/zlib_codec.py\u001b[0m in \u001b[0;36mzlib_encode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'strict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-b3e37151f3ce\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'headers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'footers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quotes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create BERTopic model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtopic_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36mfetch_20newsgroups\u001b[0;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload_if_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading 20news dataset. This may take a few minutes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 269\u001b[0;31m             cache = _download_20newsgroups(\n\u001b[0m\u001b[1;32m    270\u001b[0m                 \u001b[0mtarget_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwenty_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36m_download_20newsgroups\u001b[0;34m(target_dir, cache_path)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[0;32m---\u003e 85\u001b[0;31m     \u001b[0mcompressed_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"zlib_codec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: encoding with 'zlib_codec' codec failed (KeyboardInterrupt: )"]}],"source":["docs = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=42)['data'][:100]\n","\n","# Create BERTopic model\n","topic_model = BERTopic()\n","\n","# fit the data and tranform\n","topics, probs = topic_model.fit_transform(docs)\n","\n","# get topic information\n","topic_info = topic_model.get_topics()\n","\n","# print topic info\n","print(topic_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"--nyTvvma1w4"},"outputs":[],"source":["topic_model.get_topic_info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P55b84KIa1ze"},"outputs":[],"source":["topic_model.get_topic(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DZG2q_jXbsON"},"outputs":[],"source":["topic_model.get_document_info(docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BURoGfg_buH8"},"outputs":[],"source":["cats = ['alt.atheism', 'sci.space']\n","cat_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)['data']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e87swPZG0z1c"},"outputs":[],"source":["from hdbscan import HDBSCAN\n","\n","hdbscan_model = HDBSCAN(min_cluster_size=3, metric='euclidean',\n","                        cluster_selection_method='eom', prediction_data=True, min_samples=5)\n","new_model = BERTopic(hdbscan_model=hdbscan_model)\n","topics_new, probs_new = new_model.fit_transform(docs)\n","new_model.get_topic(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWIUsxsF2Dx4"},"outputs":[],"source":["cluster_model = KMeans(n_clusters=30)\n","new_model = BERTopic(hdbscan_model=cluster_model)\n","topics_new, probs_new = new_model.fit_transform(docs)\n","new_model.get_topic(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l1gxIgNnd6bS"},"outputs":[],"source":["new_model.get_topic_info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pMguTn4neDWP"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer\n","\n","vectorizer_model = CountVectorizer(stop_words=\"english\")\n","cluster_model = KMeans(n_clusters=30)\n","new_model1 = BERTopic(vectorizer_model=vectorizer_model)\n","topics_new, probs_new = new_model1.fit_transform(docs)\n","new_model1.get_topic(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GDy3NMVRepmR"},"outputs":[],"source":["from bertopic.vectorizers import ClassTfidfTransformer\n","\n","ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n","new_model2 = BERTopic(ctfidf_model=ctfidf_model)\n","topics_new, probs_new = new_model2.fit_transform(docs)\n","new_model2.get_topic(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G3BiuRqgXMaC"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}